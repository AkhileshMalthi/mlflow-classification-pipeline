services:
  mlflow_server:
    image: ghcr.io/mlflow/mlflow:latest
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:////mlflow/mlflow.db --default-artifact-root /mlflow/artifacts --serve-artifacts --allowed-hosts "*"
    volumes:
      - ./_mlflow_data:/mlflow
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  model_api:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow_server:5000
      - MLFLOW_ARTIFACT_URI=http://mlflow_server:5000
      - REGISTERED_MODEL_NAME=ClassificationModel
      - MODEL_STAGE=Production
    volumes:
      - ./_mlflow_data:/mlflow
    depends_on:
      mlflow_server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
